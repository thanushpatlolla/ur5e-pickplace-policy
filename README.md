*This README was generated by Claude Code*

# MuJoCo UR5e Pick and Place - Data Collection & MLP Training

A complete pipeline for collecting robot trajectory data from MuJoCo simulations and training a Multi-Layer Perceptron (MLP) to clone pick-and-place behavior. The project simulates a UR5e manipulator with Robotiq 2F85 gripper performing randomized pick-and-place tasks, then learns a policy from the collected demonstrations.

## Overview

This project consists of two main components:

1. **Data Collection**: Simulates a UR5e robot arm picking up randomly positioned and sized objects from a table and placing them at target locations. Uses inverse kinematics (IK) with the Mink library to generate smooth trajectories while avoiding collisions.

2. **Behavior Cloning**: Trains a Multi-Layer Perceptron (MLP) to map robot state and object configuration to joint velocity commands and gripper actions, learning to replicate the demonstrated pick-and-place behavior.

## Features

### Data Collection
- **Randomized Object Initialization**: Objects are randomly sized (dimensions and orientation) and placed within the robot's workspace
- **Inverse Kinematics Control**: Uses Mink for efficient IK solving with collision avoidance
- **Collision Avoidance**: Prevents gripper and arm components from colliding with the table surface
- **Velocity Limiting**: Enforces joint velocity constraints for realistic motion
- **Multi-Stage Pick-and-Place**: Executes a complete pick-and-place sequence:
  - Approach object from above
  - Descend to object
  - Grasp with gripper
  - Lift object
  - Move to target location
  - Place and release object
  - Retract
- **Automated Data Collection**: Collects 500 successful episodes in headless mode with automatic retry on failures
- **Structured Data Storage**: Saves trajectory data to compressed NPZ files with metadata

### MLP Training
- **Behavior Cloning**: Supervised learning from expert demonstrations
- **State Representation**: 22D input (joint positions/velocities, end-effector position, object pose)
- **Action Prediction**: 7D output (6 joint velocities + gripper command)
- **Data Normalization**: Automatic computation and application of normalization statistics
- **Training Infrastructure**: Complete pipeline with validation, checkpointing, early stopping, and metrics logging
- **Multi-Device Support**: Runs on CUDA, Apple Silicon (MPS), or CPU

## Project Structure

```
.
├── collect_data.py            # Data collection - collects 500 successful episodes
├── run_sim.py                 # Simulation loop with IK control, model rollout, and task execution
├── initialize_object.py       # Randomizes object size, position, and orientation
├── rotation_matrix.py         # Rotation matrix utilities for end-effector orientation
├── train.py                   # Training script - trains MLP on collected data
├── dataset.py                 # Dataset loading, preprocessing, and normalization
├── model.py                   # MLP model architecture definition with action chunking
├── config.py                  # Training configuration (hyperparameters, paths)
├── utils.py                   # Training utilities (logging, checkpointing, metrics)
├── scene.xml                  # MuJoCo scene definition
├── ur5e.xml                   # UR5e robot model configuration
├── assets/                    # 3D models and textures
├── mujoco_menagerie/          # MuJoCo model zoo (contains UR5e model)
├── robotiq_2f85/              # Robotiq 2F85 gripper model
├── data/                      # Collected trajectory datasets (.npz files)
├── checkpoints/               # Saved model checkpoints
└── logs/                      # Training logs and metrics
```

## Dependencies

### Simulation
- `mujoco` - Physics simulation engine
- `mujoco-viewer` - Interactive viewer for MuJoCo simulations
- `numpy` - Numerical computations
- `mink` - Inverse kinematics library with optimization

### Machine Learning
- `torch` - PyTorch deep learning framework
- `torchvision` - PyTorch vision utilities (optional, for future visual observations)

## Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd mujoco_pick_and_place
```

2. Create a virtual environment and install dependencies:
```bash
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install simulation dependencies
pip install mujoco mujoco-viewer numpy mink

# Install ML dependencies
pip install torch torchvision
```

## Usage

### 1. Collect Training Data

Run the data collection script to collect 500 successful pick-and-place episodes:

```bash
mjpython collect_data.py
```

This will:
- Run simulations in headless mode (faster than real-time)
- Collect 500 successful episodes with automatic retry on failures
- Save trajectory data to `data/pick_place_dataset_YYYYMMDD_HHMMSS.npz`
- Record 29D state-action data at each timestep:
  - Joint positions (6D)
  - Joint velocities (6D)
  - Commanded joint velocities (6D)
  - End-effector position (3D)
  - Object position (3D)
  - Object quaternion (4D)
  - Gripper command (1D)

Each episode includes randomized:
- Object size (width: 1-3cm, depth: 1-3cm, height: 2-5cm)
- Object placement (25-65cm from robot base)
- Object orientation (random yaw)

**Expected output**: ~1.17M timesteps across 500 episodes, saved as compressed NPZ file (~50-100 MB)

### 2. Train the MLP Policy

After collecting data, train the behavior cloning policy:

```bash
python train.py
```

Or with custom parameters:

```bash
python train.py --data_path data/pick_place_dataset_20251224_002746.npz \
                --batch_size 512 \
                --learning_rate 3e-4 \
                --epochs 100
```

This will:
- Load and split data into train (80%), validation (10%), test (10%) sets
- Compute normalization statistics from training data
- Train a 3-layer MLP (22D input → 256D hidden → 7D output)
- Log metrics to console and `logs/metrics_YYYYMMDD_HHMMSS.json`
- Save checkpoints to `checkpoints/`:
  - `best_model.pth` - Best validation loss
  - `latest_model.pth` - Most recent epoch
  - `checkpoint_epoch_N.pth` - Periodic saves every 5 epochs
- Apply early stopping if no improvement for 10 epochs

**Training time**: ~10-15 minutes on Apple Silicon M1/M2, ~5 minutes on NVIDIA GPU

### 3. Run Simulation with Trained Model

After training, you can watch the robot perform pick-and-place using only the model's predictions (no inverse kinematics or motion planning):

```bash
mjpython run_sim.py --mode model
```

This runs the simulation using the trained model at `checkpoints/best_model.pth` by default. The robot will follow the model's predicted joint velocities at each timestep.

**Options**:
- `--checkpoint PATH`: Specify a different model checkpoint (default: `checkpoints/best_model.pth`)
- `--sleep SECONDS`: Control visualization speed (default: 0.01s per step)
- `--headless`: Run without visualization
- `--actions-per-query N`: Number of steps to execute before recomputing the action chunk (default: `1`). The model predicts `chunk_size` future actions at once, but only executes `actions_per_query` of them before re-querying the model. This allows for temporal ensembling and reduces computation frequency.

**Examples**:

Watch the model-based rollout (default speed):
```bash
mjpython run_sim.py --mode model
```

Watch in slow motion:
```bash
mjpython run_sim.py --mode model --sleep 0.005
```

Use a specific checkpoint file:
```bash
mjpython run_sim.py --mode model --checkpoint checkpoints/checkpoint_epoch_50.pth
```

Use a specific timestamp directory (loads best_model.pth from that run):
```bash
mjpython run_sim.py --mode model --checkpoint 20260101_072815
```

Control action chunk recomputation frequency:
```bash
mjpython run_sim.py --mode model --actions-per-query 1 --sleep 0.02
```

Compare with the original IK-based approach:
```bash
mjpython run_sim.py --mode ik --sleep 0.01
```

### Key Configuration Parameters

In `config.py`:
- **Model architecture**: 22 → 256 → 256 → 256 → 7 (3 hidden layers)
- **Batch size**: 512 (~2,277 batches/epoch)
- **Learning rate**: 3e-4 (AdamW optimizer)
- **Weight decay**: 1e-4
- **Early stopping patience**: 10 epochs
- **Device**: Auto-detected (CUDA > MPS > CPU)

In `run_sim.py`:
- **Time step**: Defined by `model.opt.timestep`
- **Waypoint threshold**: 0.02m (2cm)
- **Gripper control**: Binary (0 = open, 255 = close)
- **Collision avoidance margin**: 0.01m minimum distance
- **Action chunk size**: Number of future actions predicted at once (default: 10, from `config.py`)
- **Actions per query**: Number of steps executed before recomputing action chunk (default: `1`)

## How It Works

### Simulation Modes

The project supports two simulation modes in `run_sim.py`:

#### 1. IK Mode (--mode ik)
The original implementation using inverse kinematics and motion planning:
- Uses Mink library for IK solving
- Follows predefined waypoints with collision avoidance
- Employs velocity limits and configuration constraints
- This mode generates the expert demonstrations for training

#### 2. Model Mode (--mode model)
Pure model-based control using the trained MLP:
- Loads trained model checkpoint with normalization statistics
- Uses action chunking: the model predicts `chunk_size` future actions at once (default: 10)
- Action execution loop:
  1. Observes current state (joint pos/vel, EE pos, object pos/quat, object size, gripper state)
  2. Normalizes input using training statistics
  3. Predicts `chunk_size` future actions (joint velocities + gripper commands) via MLP forward pass
  4. Executes `actions_per_query` steps from the predicted chunk (default: `1`)
  5. After executing `actions_per_query` steps, re-queries the model with updated state
  6. Denormalizes output and applies commands
  7. Steps simulation forward
- The `--actions-per-query` parameter controls how many steps are executed before recomputing the action chunk, enabling temporal ensembling and reducing model query frequency
- No IK solving, no motion planning, no predefined waypoints
- Pure reactive policy based on current observations

### Data Collection Pipeline

#### Object Randomization
The `initialize_object()` function (initialize_object.py:4) creates variation in:
- Object dimensions (cuboid with random width, depth, height)
- Object placement (random position on table within reachable area)
- Object orientation (random yaw rotation)

#### Trajectory Generation
The simulation uses task-space control with inverse kinematics:
1. **End-Effector Task**: Targets specific 3D positions and orientations
2. **Posture Task**: Maintains preferred joint configurations
3. **Limits**: Joint limits, velocity limits, and collision avoidance

#### Pick-and-Place Sequence
Ten waypoints guide the robot through the task (run_sim.py:115):
0. High above object (40cm)
1. Medium above object (10cm) - enables vertical approach
2. At object center - precise alignment
3. Grasp object - gripper closes
4. Lift object (40cm above initial position)
5. High above target location
6. Medium above target (10cm) - controlled descent
7. Near placement (2cm above table) - prevents premature release
8. At target - gripper opens
9. Retract upward

#### Orientation Control
The `get_rotation_matrix()` function (rotation_matrix.py:76) computes end-effector orientation:
- During pickup (steps 1-3): Aligns gripper vertically and matches object orientation
- Other steps: Maintains vertical gripper orientation

### Training Pipeline

#### Data Format
The collected NPZ files contain:
- **Episodes**: `episode_0`, `episode_1`, ..., `episode_N` (variable-length arrays)
- **Metadata**: Statistics about the dataset (episode count, success rate, lengths)

Each episode array has shape `(timesteps, 29)`:
- Columns 0-5: Joint positions
- Columns 6-11: Joint velocities
- Columns 12-17: Commanded joint velocities (targets for learning)
- Columns 18-20: End-effector position
- Columns 21-23: Object position
- Columns 24-27: Object quaternion
- Column 28: Gripper command {0, 255}

#### Model Architecture
The MLP (model.py) uses a simple fully-connected architecture:
- **Input**: 22D state (joint pos/vel, EE pos, obj pos/quat)
- **Hidden**: 3 layers of 256 units with ReLU activation
- **Output**: 7D action (6 joint velocities + gripper)
- **Parameters**: ~200K trainable parameters

#### Training Process
1. **Data Loading**: Episodes loaded from NPZ file (dataset.py:7)
2. **Splitting**: 80% train, 10% validation, 10% test (dataset.py:31)
3. **Normalization**: Mean/std computed from training data (dataset.py:111)
4. **Optimization**: AdamW with MSE loss on normalized outputs
5. **Validation**: Track joint velocity MSE and gripper accuracy
6. **Checkpointing**: Save best model based on validation loss
7. **Early Stopping**: Stop if no improvement for 10 epochs

## Future Work

- **Policy Deployment**: Deploy trained MLP in simulation and evaluate success rate
- **Sim-to-Real Transfer**: Test policy on real UR5e hardware
- **Visual Observations**: Add camera rendering for vision-based policies (CNN or ViT encoder)
- **Curriculum Learning**: Gradually increase task difficulty (object size variation, stacking)
- **Advanced Architectures**: Experiment with transformers, diffusion policies, or recurrent models
- **Multi-Task Learning**: Extend to multiple object shapes and task variations
- **Domain Randomization**: Add visual/physical randomization for better generalization

## Notes

### Simulation
- The UR5e has a maximum reach of 85cm, but this implementation limits it to 65cm for reliability
- Contact detection between gripper pads and object ensures successful grasping
- The simulation waits for stable gripper-object contact before proceeding to lift
- Data collection runs in headless mode for faster-than-realtime execution

### Training
- Normalization statistics (mean/std) are computed from training data and saved with checkpoints
- The gripper output is not normalized (binary 0/1 after scaling from 0/255)
- AdamW optimizer with weight decay provides better generalization than standard Adam
- Early stopping prevents overfitting on long training runs
- Checkpoints include normalization stats for deployment

### Performance
- Expected training loss: ~1e-4 to 1e-5 MSE on normalized outputs
- Gripper accuracy: typically >99% (binary classification is easier than continuous control)
- Joint velocity prediction is the primary challenge

---